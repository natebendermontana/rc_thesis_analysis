---
title: "Thesis Analysis"
author: "Nate Bender"
date: "2/16/2022"
note: "Nationally-representative survey; conducted Aug 3-9, 2020"
output: html_document
---

```{r setup, include=F}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load packages and data, eval=T, echo=F, include=F}
### Packages / libraries / load data & filter rejected 
library(DescTools)
library(broom)
library(brant)
library(tidyr)
library(ResourceSelection)  #hoslem.test
library(psych)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(ggfortify)
library(ggcorrplot)
library(ggpubr)
library(GPArotation)
library(ltm)
library(car)
library(MASS)
library(Hmisc)
library(ROCR)
library(plotROC)
library(pROC)
library(pscl)
library(blorr)

```



```{r, eval=T, echo=F, include=T}
regression_clean <- read.csv("/Users/natebender/Desktop/Repo/RCthesisanalysis/cleandata/perenial_complete_for_analysis.csv", header=TRUE, stringsAsFactors = TRUE)
```

```{r, eval=T, echo=F, include=T}

regression_clean <- regression_clean %>% 
  mutate(sr_12a_actions_contacted_officials_binary = 
           case_when(
             sr_12a_actions_contacted_officials == "morethanonce" ~ 1,
             sr_12a_actions_contacted_officials == "once" ~ 1,
             sr_12a_actions_contacted_officials == "nocontact" ~ 0,
             TRUE ~ -1 # Just to be careful
           ))

# set reference groups for regression
regression_clean <- regression_clean %>% 
  mutate(race_white_dumvar = fct_relevel(race_white_dumvar,"race_white"),
         children_dumvar = fct_relevel(children_dumvar,"children"),
         sr_75_religion_dumvar = fct_relevel(sr_75_religion_dumvar, "religious"),
         gender_dumvar = fct_relevel(gender_dumvar, "male"),
         sr_56_marital_status = fct_relevel(sr_56_marital_status, "married_partner"),
         sr_61_education = fct_relevel(sr_61_education, "assocdeg_orlower"),
         sr_71_employment_status = fct_relevel(sr_71_employment_status, "workfull"),
         sr_72_income = fct_relevel(sr_72_income, "under100k"),
         sr_79_political_leaning = fct_relevel(sr_79_political_leaning, "liberal"),
         sr_7_believe_about_climate_change = fct_relevel(sr_7_believe_about_climate_change,
                                                        "excl_human"))

```

```{r}
#describe(regression_clean)

describe(regression_clean$sr_61_education)

```


```{r, eval=T, echo=F, include=T}
# reduce dataset down to just variables needed for saturated model, in order to make code later on much cleaner. 
data_for_regression <- regression_clean %>% 
  dplyr::select(sr_12a_actions_contacted_officials_binary,
    age_true,
    race_white_dumvar,
    gender_dumvar,
    children_dumvar,
    sr_75_religion_dumvar,
    sr_56_marital_status,
    sr_61_education,
    sr_71_employment_status,
    sr_72_income,
    sr_79_political_leaning,
    sr_7_believe_about_climate_change,
    descdynamicnorms_comp,
    desccontactnorms_all_comp,
    descrolemodelnorms_all_comp,
    injunctcontactnorms_all_comp,
    injunctmotivation_all_comp,
    cimbenefits_comp,
    cimperceivedrisk_comp,
    sr_10_harm_you_personally_reversed,
    sr_11_harm_future_generations_reversed,
    sr_21a_effective_actions_contacting_officials,
    efficacy_effectiveness_all_comp,
    efficacy_competresp_all_comp,
    behatt_admirablegood_comp,
    behatt_usefulpleasantsensible_comp,
    behatt_coolexcitingeasy_comp,
    sr_30_easy_to_call,
    sr_31_able_to_call,
    sr_41a_right_to_modify,
    sr_41b_laws_of_nature,
    sr_41c_ingenuity,
    sr_41d_impotent,
    sr_41e_govt_do_more,
    sr_41f_equity)


# describe(data_for_regression)
```

```{r}
n.runs <- 100
set.seed(19881)
```


```{r}
if(exists("results")){
  rm(results)
}

for(i in 1:n.runs){
  # ensures even split on response variable. 
  default_idx = caret::createDataPartition(as.factor(data_for_regression$sr_12a_actions_contacted_officials_binary), p = 0.75, list = FALSE)
  default_train = data_for_regression[default_idx, ]
  default_test = data_for_regression[-default_idx, ]
  
  logit_contacted <- glm(sr_12a_actions_contacted_officials_binary ~
                           age_true + race_white_dumvar + gender_dumvar + children_dumvar +
                           sr_75_religion_dumvar + sr_56_marital_status + sr_61_education +
                           sr_71_employment_status + sr_72_income +
                           sr_79_political_leaning + sr_7_believe_about_climate_change +
                           descdynamicnorms_comp + desccontactnorms_all_comp +
                           descrolemodelnorms_all_comp + injunctcontactnorms_all_comp +
                           injunctmotivation_all_comp + cimbenefits_comp +
                           cimperceivedrisk_comp + sr_10_harm_you_personally_reversed +
                           sr_11_harm_future_generations_reversed +
                           sr_21a_effective_actions_contacting_officials +
                           efficacy_effectiveness_all_comp + efficacy_competresp_all_comp +
                           behatt_admirablegood_comp + behatt_usefulpleasantsensible_comp +
                           behatt_coolexcitingeasy_comp +
                           sr_30_easy_to_call + sr_31_able_to_call + sr_41a_right_to_modify +
                           sr_41b_laws_of_nature + sr_41c_ingenuity + sr_41d_impotent +
                           sr_41e_govt_do_more + sr_41f_equity, 
                         data = default_train, 
                         family=binomial)
  
  
  logit_contacted_aic <- stepAIC(logit_contacted, direction="backward")
  
  if (i == 1) {
    results <- tidy(logit_contacted_aic) %>% 
      mutate(simulation=i)
    
  } else {
    results <- results %>% 
      bind_rows(tidy(logit_contacted_aic) %>% 
                  mutate(simulation=i))
    
  }
}
```

```{r}
df <- results %>% 
  dplyr::group_by(term) %>% 
  dplyr::summarize(n = n(),
            mean_est = mean(estimate),
            min_est = min(estimate),
            max_est = max(estimate),
            mean_sd = mean(std.error)) %>% 
  mutate(fraction_of_models = n/n.runs) %>%
  arrange(desc(n))

# print(df, n = Inf)

write.csv(df,"/Users/natebender/Desktop/repo/RCthesisanalysis/output_tables/ThesisPastactionregmodel_simulations.csv", row.names = TRUE)

```

```{r}
# FINAL MODEL BUILT USING TRAINING DATA
# # Grabbing the 9 EVs that appear in half or more of the simulations
logit_final <- glm(sr_12a_actions_contacted_officials_binary~
                     cimbenefits_comp+
                     desccontactnorms_all_comp+
                     age_true+
                     cimperceivedrisk_comp+
                     sr_31_able_to_call+
                     sr_41c_ingenuity+
                     sr_10_harm_you_personally_reversed+
                     sr_11_harm_future_generations_reversed+
                     injunctcontactnorms_all_comp,
                   data=default_train,family=binomial)

logit_final_aic <- stepAIC(logit_final, direction="backward")

# Injunctive norms and human ingenuity get dropped from the model
summary(logit_final_aic)

confint(logit_final_aic)

```

```{r}
logit_final_test <- glm(sr_12a_actions_contacted_officials_binary~
                     cimbenefits_comp+
                     desccontactnorms_all_comp+
                     age_true+
                     cimperceivedrisk_comp+
                     sr_31_able_to_call+
                     sr_41c_ingenuity+
                     sr_10_harm_you_personally_reversed+
                     sr_11_harm_future_generations_reversed+
                     injunctcontactnorms_all_comp,
                   data=default_test,family=binomial)

logit_final_test_aic <- stepAIC(logit_final_test, direction="backward")

summary(logit_final_test_aic)
```


```{r}
# Create decile-wise lift chart
library(blorr)
gt <- blorr::blr_gains_table(logit_final)

blr_decile_lift_chart(
  gt,
  xaxis_title = "Decile",
  yaxis_title = "Decile Mean / Global Mean",
  title = "Decile Lift Chart",
  bar_color = "blue",
  text_size = 3.5,
  text_vjust = -0.3,
  print_plot = TRUE
)

logit_final %>%
  blr_gains_table() %>%
  blr_decile_lift_chart()

# the kappa statistic is a measure of how closely the instances classified by the machine learning classifier matched the data labeled as ground truth, controlling for the accuracy of a random classifier as measured by the expected accuracy
blr_confusion_matrix(logit_final_test)


blr_model_fit_stats(logit_final_test)

# Variable inflation factors (rule of thumb: under 2 shows no collinearity)
vif(logit_final_test)

lrtest(logit_final_aic, logit_final) #not sig different than saturated model, all else being equal -- go with simpler model
lrtest(logit_final_aic) #sig diff from null model, which is good


#Hosmer-Lemeshow GOF test --> sensitive to group number, not good for binary predictors
#https://stats.stackexchange.com/questions/186219/how-many-groups-to-use-in-hosmer-and-lemeshow-test
for (i in 4:15) {
  print(hoslem.test(default_train$sr_12a_actions_contacted_officials_binary, fitted(logit_final_aic), g=i) $p.value)
} #no sig values --> safe to say that there is no evidence of poor model fit


par(mfrow=c(2,2)) #this command creates a plot grid with 2 rows and 2 columns to view the diagnostic plots all at once
plot(logit_final_aic)
```


### Graphing logistic regression
```{r}

m1_log_preds = tidy(logit_final_aic, conf.int = T, exponentiate = T) %>%
    mutate(Model = "Past contact")
m1_log_predstest <- subset(m1_log_preds, term !="(Intercept)") #& p.value < 0.05)  # remove intercept
# write.csv(m1_log_predstest,"/Users/natebender/Desktop/ThesisPastactionregmodel.csv", row.names = TRUE)

m1_log_predstest <- m1_log_predstest %>%
 mutate(term = c("CIM benefits", "Descriptive contact norms", "Age", "Perceived risk", "Efficacy: able to call", "CC personal harm",  "CC harm future generations"))

# Specify the width of your confidence intervals
interval1 <- -qnorm((1-0.9)/2)  # 90% multiplier
interval2 <- -qnorm((1-0.95)/2)  # 95% multiplier

# Plot
pdf("ThesisPastaction_oddsratio_plot.pdf") # starts writing a PDF to file
png("ThesisPastaction_oddsratio_plot.png") # starts writing a PDF to file
zp1 <- ggplot(m1_log_predstest, aes(colour = Model))
zp1 <- zp1 + geom_hline(yintercept = 1, colour = gray(1/2), lty = 2)
zp1 <- zp1 + geom_linerange(aes(x = term, ymin = conf.low,
                                ymax = conf.high),
                            lwd = 1, position = position_dodge(width = 1/2))
zp1 <- zp1 + geom_pointrange(aes(x = term, y = estimate, ymin = conf.low,
                                 ymax = conf.high),
                             lwd = 1/2, position = position_dodge(width = 1/2),
                             shape = 21, fill = "WHITE")
zp1 <- zp1 + coord_flip() + theme_bw()
INTzp1_log <- zp1 + ggtitle("What influences past representative contact?") + ylab("Odds Ratio") + xlab("Variable")
print(INTzp1_log)  # The trick to these is position_dodge().
dev.off()

# write.csv(m1_log_predstest,"/Users/natebender/Desktop/ThesisPastactionregmodel.csv", row.names = TRUE)

```

```{r}
print(INTzp1_log) # prints plot to screen after it's been saved to file
```


```{r}
# Log Odds visualization

m1_log_preds = tidy(logit_final_aic, conf.int = T) %>%
    mutate(Model = "Past contact")
m1_log_predstest <- subset(m1_log_preds, term !="(Intercept)") #& p.value < 0.05)  # remove intercept
m1_log_predstest <- m1_log_predstest %>%
 mutate(term = c("CIM benefits", "Descriptive contact norms", "Age", "Perceived risk", "Efficacy: able to call", "CC personal harm",  "CC harm future generations"))

# Specify the width of your confidence intervals
interval1 <- -qnorm((1-0.9)/2)  # 90% multiplier
interval2 <- -qnorm((1-0.95)/2)  # 95% multiplier

# Plot
pdf("ThesisPastaction_logodds_plot.pdf") # starts writing a PDF to file
png("ThesisPastaction_logodds_plot.png") # starts writing a PDF to file
zp1 <- ggplot(m1_log_predstest, aes(colour = Model))
zp1 <- zp1 + geom_hline(yintercept = 0, colour = gray(1/2), lty = 2)
zp1 <- zp1 + geom_linerange(aes(x = term, ymin = conf.low,
                                ymax = conf.high),
                            lwd = 1, position = position_dodge(width = 1/2))
zp1 <- zp1 + geom_pointrange(aes(x = term, y = estimate, ymin = conf.low,
                                 ymax = conf.high),
                             lwd = 1/2, position = position_dodge(width = 1/2),
                             shape = 21, fill = "WHITE")
zp1 <- zp1 + coord_flip() + theme_bw()
INTzp1_log <- zp1 + ggtitle("What influences past representative contact?") + ylab("Beta (log odds) estimate") + xlab("Variable")
print(INTzp1_log)  # The trick to these is position_dodge().
dev.off()

# write.csv(m1_log_predstest,"/Users/natebender/Desktop/ThesisPastactionregmodel.csv", row.names = TRUE)
print(INTzp1_log)  # The trick to these is position_dodge().

```






### IGNORE FOR THESIS - USING CARET PACKAGE FOR MODELING
```{r, eval=T, echo=F, include=T}
# 35 variables including RV
# 
# ctrl <- trainControl(method = "cv", number = 5)  # five cross-validations
# 
# # saturated logistic regression
# logit_contacted_saturated <- caret::train(
#   sr_12a_actions_contacted_officials_binary ~ .,
#   data = default_train,
#   method = "glm",
#   family = "binomial",
#   trControl = ctrl
#   )
# 
# # Logistic regression via backwards stepwise AIC selection
# logit_contacted_test <- caret::train(
#   sr_12a_actions_contacted_officials_binary ~ .,
#   data = default_train,
#   method = "glmStepAIC",
#   direction = "backward",
#   family = "binomial",
#   trControl = ctrl
#   )
# 
# # Multinomial logistic regression via glmnet package
# # Extension of glm models with built-in variable selection. Uses both lasso and ridge penalization.
# mnl <- caret::train(
#   sr_12a_actions_contacted_officials_binary ~ .,
#   data = default_train, 
#   method = "glmnet",
#   trControl = ctrl
#   )
# 
# 
# # Random forest model 
# # random forests are an ensemble learning method for classification and regression that operate by constructing a lot of decision trees at training time and outputting the class that is the mode of the classes output by individual trees.
# rf <- caret::train(
#   sr_12a_actions_contacted_officials_binary ~ .,
#   data = default_train,
#   method = "rf",
#   trControl = ctrl
# )
# 
# 
# # # XGBoost
# # # xgboost only deals with numeric data â€” how best to manipulate data? Force all factors to numeric?
# # library(mlr)
# # library(xgboost)
# # 
# # traintask <- makeClassifTask(data = default_train, target = "sr_12a_actions_contacted_officials_binary", positive = 1)
# # testtask <- makeClassifTask(data = default_test, target = "sr_12a_actions_contacted_officials_binary")
# # 
# # xgb_learner <- makeLearner(
# #   "classif.xgboost",
# #   predict.type = "response",
# #   par.vals = list(
# #     objective = "binary:logistic",
# #     eval_metric = "error",
# #     nrounds = 200
# #   )
# # )
# # 
# # xgb_model <- train(xgb_learner, task = traintask)
# 


```

```{r}
# summary(logit_contacted_test)
```


```{r}
# prepared_input <- prepare_scores_and_ntiles(datasets=list("default_train","default_test"),
#   dataset_labels = list("train data","test data"),
#   models = list("logit_contacted_test", "mnl", "rf"),
#   model_labels = list("LogitStepAIC", "Glmnet", "Randomforest"),
#   target_column= "sr_12a_actions_contacted_officials_binary")
# 
# forplot <- plotting_scope(
#   prepared_input,
#   scope = "compare_models",
#   select_dataset_label = "test data", 
#   select_targetclass = NA)
# 
# forplotindividual <- plotting_scope(
#   prepared_input,
#   select_model_label = "LogitStepAIC", 
#   select_dataset_label = "test data", 
#   select_targetclass = NA)
# 
# # all four plots together
# plot_multiplot(
#   data = forplotindividual
# )
# 
# # just cumulative lift 
# plot_cumlift(
#   data = forplotindividual,
#   highlight_ntile = 2,
# )
# 
# # just cumulative response
# plot_cumresponse(
#   data = forplot,
#   highlight_ntile = 2
# )

```


```{r}
# # random forest interpretation
# plot(rf)
# 
# rf_predictions <- predict(rf, default_test)
# 
# # "accuracy" is accuracy on training data. 
# confusionMatrix(table(default_test[,"sr_12a_actions_contacted_officials_binary"],rf_predictions))
# 
# varImp(rf)
# # somehow limit to just the significant variables?
# plot(varImp(rf))

```


```{r}
# LogitAIC PREDICTED V ACTUAL TESTING
# test_predicted <- predict(logit_contacted_test, default_test)
# expected <- default_test$sr_12a_actions_contacted_officials_binary
# 
# table(expected)
# table(test_predicted)
# 
# confusionMatrix(test_predicted, expected)

```

```{r}
# Variable importance

# is there a way to get this to show only the significant variables in the final model?
# ggplot(varImp(logit_contacted_test))
```


```{r, eval=T, echo=F, include=T}
# Variable inflation factors (rule of thumb: under 4 is good)
# vif(logit_contacted_test$finalModel)

```


